{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "4f23f81b-bc5f-45a2-9f92-3c4a4edba515",
   "metadata": {},
   "source": [
    "# Model Improvement"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f356cac8",
   "metadata": {},
   "source": [
    "## Feature selection"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5d4ca07e-9ebd-4538-a858-961208635382",
   "metadata": {},
   "source": [
    "Importing the dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "4da432ea-440e-465d-a8a6-75adda81d8da",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   type                                               text\n",
      "0   ham  Hope you are having a good week. Just checking in\n",
      "1   ham                            K..give back my thanks.\n",
      "2   ham        Am also doing in cbe only. But have to pay.\n",
      "3  spam  complimentary 4 STAR Ibiza Holiday or £10,000 ...\n",
      "4  spam  okmail: Dear Dave this is your final notice to...\n",
      "Shape: (5559, 2) \n",
      "\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "from nltk.corpus import stopwords\n",
    "import gensim\n",
    "import numpy as np\n",
    "\n",
    "\n",
    "dataset=pd.read_csv(\"sms_spam.csv\")\n",
    "\n",
    "print(dataset.head())\n",
    "print (\"Shape:\", dataset.shape, '\\n')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dad401ac-e944-43e1-8923-d8266aaa6a02",
   "metadata": {},
   "source": [
    "Preprocessing function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "b1d52a1a-4062-49bb-bfce-16234df64cc3",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "def transformText(text):\n",
    "    stops = set(stopwords.words(\"english\"))\n",
    "    # Convert text to lowercase\n",
    "    text = text.lower()\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Removing all the stopwords\n",
    "    filtered_words = [word for word in text.split() if word not in stops]\n",
    "    # Preprocessed text after stop words removal\n",
    "    text = \" \".join(filtered_words)\n",
    "    # Remove the punctuation\n",
    "    text = gensim.parsing.preprocessing.strip_punctuation(text)\n",
    "    # Strip all the numerics\n",
    "    text = gensim.parsing.preprocessing.strip_numeric(text)\n",
    "    # Removing all the words with < 3 characters\n",
    "    text = gensim.parsing.preprocessing.strip_short(text, minsize=3)\n",
    "    # Strip multiple whitespaces\n",
    "    text = gensim.corpora.textcorpus.strip_multiple_whitespaces(text)\n",
    "    # Stemming\n",
    "    return gensim.parsing.preprocessing.stem_text(text)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e54c2c02-a7e1-4530-8a32-13b190dd13fc",
   "metadata": {},
   "source": [
    "Preprocessing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "f24a3518-0949-4b60-b370-62c1bbb29f36",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0                                 hope good week check\n",
      "1                                      give back thank\n",
      "2                                    also cbe onli pai\n",
      "3    complimentari star ibiza holidai cash need urg...\n",
      "4    okmail dear dave final notic collect tenerif h...\n",
      "Name: text, dtype: object\n"
     ]
    }
   ],
   "source": [
    "#applies transformText to all rows of text\n",
    "dataset['text'] = dataset['text'].map(transformText)\n",
    "print(dataset['text'].head())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "39e54308-cd7c-466a-9828-821b1026deb1",
   "metadata": {},
   "source": [
    "Creating training and test set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "4989bb87-87e3-48a0-a366-b33e257ea733",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Training Sample Size: 3724   Test Sample Size: 1835\n"
     ]
    }
   ],
   "source": [
    "## Split the data\n",
    "from sklearn.model_selection import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(dataset['text'], dataset['type'],\n",
    "                                                    test_size=0.33, random_state=10)\n",
    "\n",
    "print (\"Training Sample Size:\", len(X_train), ' ', \"Test Sample Size:\" ,len(X_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "28ced4b4-1b78-47dc-8a8e-e6b96aac274a",
   "metadata": {},
   "source": [
    "Creating a tf-idf model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "d612bddf-29eb-4470-9e35-5dc3f1a90ce2",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of TF-IDF vector : (3724, 5056)\n"
     ]
    }
   ],
   "source": [
    "#Build the counting corpus\n",
    "from sklearn.feature_extraction.text import CountVectorizer\n",
    "count_vect = CountVectorizer()\n",
    "X_train_counts = count_vect.fit_transform(X_train)\n",
    "\n",
    "## Get the TF-IDF vector representation of the data\n",
    "from sklearn.feature_extraction.text import TfidfTransformer\n",
    "tfidf_transformer = TfidfTransformer()\n",
    "X_train_tfidf = tfidf_transformer.fit_transform(X_train_counts)\n",
    "print ('Dimension of TF-IDF vector :' , X_train_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9007df80-8d5e-42e1-9c90-433b58dc4061",
   "metadata": {},
   "source": [
    "Performing feature selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5d172ecf-0634-4366-81a0-483dffed5e78",
   "metadata": {
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of TF-IDF vector : (3724, 2000)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectKBest\n",
    "from sklearn.feature_selection import chi2\n",
    "\n",
    "#selecting the best 2000 features\n",
    "selector = SelectKBest(chi2, k=2000)\n",
    "X_new=selector.fit_transform(X_train_tfidf, y_train)\n",
    "print ('Dimension of TF-IDF vector :' , X_new.shape)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6c5aac33",
   "metadata": {},
   "source": [
    "Select the top k% features"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "c6722f79",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Dimension of TF-IDF vector : (3724, 2022)\n"
     ]
    }
   ],
   "source": [
    "from sklearn.feature_selection import SelectPercentile\n",
    "from sklearn.feature_selection import chi2\n",
    "selector = SelectPercentile(chi2,percentile=40)\n",
    "X_new=selector.fit_transform(X_train_tfidf, y_train)\n",
    "print ('Dimension of TF-IDF vector :' , X_new.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "b18ba5e6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'spam' 'ham' 'spam']\n",
      "0.9722070844686649\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Fitting the model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_new, y_train)\n",
    "\n",
    "\n",
    "#Performing the prediction\n",
    "\n",
    "#indexing the test set\n",
    "X_new_counts = count_vect.transform(X_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "# folds the test set into the selected features\n",
    "# (i.e., it removes unused features)\n",
    "X_new_sel=selector.transform(X_new_tfidf)\n",
    "#performing the actual prediction\n",
    "predicted = clf.predict(X_new_sel)\n",
    "\n",
    "print(predicted)\n",
    "print(np.mean(predicted==y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bc91d560",
   "metadata": {},
   "source": [
    "Printing metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "2bd217eb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.97      1.00      0.98      1583\n",
      "        spam       0.99      0.81      0.89       252\n",
      "\n",
      "    accuracy                           0.97      1835\n",
      "   macro avg       0.98      0.90      0.94      1835\n",
      "weighted avg       0.97      0.97      0.97      1835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,predicted))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0e98c2f",
   "metadata": {},
   "source": [
    "## Training set rebalancing"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a0322cd7",
   "metadata": {},
   "source": [
    "### Undersampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "05393039",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'ham': 495, 'spam': 495})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.under_sampling import RandomUnderSampler\n",
    "from collections import Counter\n",
    "# instantiates the undersampler. “majority” means that \n",
    "# the majority class will be undersampled to match the minority one\n",
    "undersample = RandomUnderSampler(sampling_strategy='majority')\n",
    "# undersamples the training set\n",
    "X_new_train, y_train = undersample.fit_resample(X_train_tfidf, y_train)\n",
    "# prints the dataset composition\n",
    "counter=Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9c25ee5e",
   "metadata": {},
   "source": [
    "### Random oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "67510bd4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'spam': 3229, 'ham': 3229})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from collections import Counter\n",
    "#instantiate the random oversampler class. \"minority\" means that the \n",
    "# minority class will be oversampled to match the majority class\n",
    "oversample = RandomOverSampler(sampling_strategy='minority')\n",
    "\n",
    "# Rebalances the training set by resampling \n",
    "X_new_train, y_train = oversample.fit_resample(X_train_tfidf, y_train)\n",
    "# prints the dataset composition\n",
    "counter=Counter(y_train)\n",
    "print(counter)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "224a611f",
   "metadata": {},
   "source": [
    "### SMOTE oversampling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "be80a80f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Counter({'spam': 3229, 'ham': 3229})\n"
     ]
    }
   ],
   "source": [
    "from imblearn.over_sampling import SMOTE\n",
    "from collections import Counter\n",
    "\n",
    "#instantiate the SMOTE oversampler\n",
    "oversample = SMOTE()\n",
    "\n",
    "# Rebalances the training set by creating artificial instances\n",
    "# of the minority class.\n",
    "X_new_train, y_train = oversample.fit_resample(X_train_tfidf, y_train)\n",
    "# prints the dataset composition\n",
    "counter=Counter(y_train)\n",
    "print(counter)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "98134013",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['ham' 'ham' 'ham' ... 'spam' 'ham' 'spam']\n",
      "0.9694822888283379\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "         ham       0.99      0.97      0.98      1583\n",
      "        spam       0.84      0.97      0.90       252\n",
      "\n",
      "    accuracy                           0.97      1835\n",
      "   macro avg       0.92      0.97      0.94      1835\n",
      "weighted avg       0.97      0.97      0.97      1835\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.naive_bayes import MultinomialNB\n",
    "# Fitting the model\n",
    "clf = MultinomialNB()\n",
    "clf.fit(X_new_train, y_train)\n",
    "\n",
    "\n",
    "#Performing the prediction\n",
    "\n",
    "#indexing the test set\n",
    "X_new_counts = count_vect.transform(X_test)\n",
    "X_new_tfidf = tfidf_transformer.transform(X_new_counts)\n",
    "\n",
    "#performing the actual prediction\n",
    "predicted = clf.predict(X_new_tfidf)\n",
    "\n",
    "print(predicted)\n",
    "print(np.mean(predicted==y_test))\n",
    "from sklearn import metrics\n",
    "print(metrics.classification_report(y_test,predicted))"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}